{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple feedforward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to code the simple feedforward neural network shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"network.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function used: f(x) = 1 / (1 + e^(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to represnt a neuron\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        # output = sigmoid((inputs).(weights) + bias)\n",
    "        result = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "# Checking Neuron class\n",
    "weights = np.array([0,1])\n",
    "bias = 4\n",
    "neuron1 = Neuron(weights, bias)\n",
    "x = np.array([2,3])\n",
    "print('Output: ', neuron1.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    '''\n",
    "    This neural network contains\n",
    "    --> 2 inputs x1 and x2\n",
    "    --> A hidden layer with 2 neurons h1 and h2\n",
    "    --> An output layer with a single neuron o1\n",
    "    \n",
    "    Each neuron has the same weights and bias:\n",
    "    --> w = [0, 1]\n",
    "    --> b = 0 \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Weights and bias\n",
    "        weights = np.array([0,1])\n",
    "        bias = 0\n",
    "        \n",
    "        # Creating a neural network\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        # Output of h1 and h2\n",
    "        output_h1 = self.h1.feedforward(inputs)\n",
    "        output_h2 = self.h2.feedforward(inputs)\n",
    "        \n",
    "        # Final output (o1)\n",
    "        output_o1 = self.o1.feedforward(np.array([output_h1, output_h2]))\n",
    "        return output_o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of created network: 0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "# Checking the neuralNetwork class\n",
    "\n",
    "network = neuralNetwork()\n",
    "x = np.array([2,3])\n",
    "out = network.feedforward(x)\n",
    "print('Output of created network:', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2099847715141283\n"
     ]
    }
   ],
   "source": [
    "print(np.random.normal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This NN guesses the gender based on the input weight and height of a person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'image2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_sigmoid(x):\n",
    "    # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "    fx = sigmoid(x)\n",
    "    return fx *(1-fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    # Both y_true and y_pred are numpy arrays. y_true is the expected output and y_pred is the predicted output.\n",
    "    return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    '''\n",
    "    This neural network contains\n",
    "    --> 2 inputs x1 and x2\n",
    "    --> A hidden layer with 2 neurons h1 and h2\n",
    "    --> An output layer with a single neuron o1\n",
    "    \n",
    "    Each neuron has the different weights and bias:\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Weights- Randomly assigning the weights\n",
    "        self.w1 = np.random.normal()\n",
    "        self.w2 = np.random.normal()\n",
    "        self.w3 = np.random.normal()\n",
    "        self.w4 = np.random.normal()\n",
    "        self.w5 = np.random.normal()\n",
    "        self.w6 = np.random.normal()\n",
    "        \n",
    "        # Bias\n",
    "        self.b1 = np.random.normal()\n",
    "        self.b2 = np.random.normal()\n",
    "        self.b3 = np.random.normal()\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        # x is a numpy array: x[0] is weight(minus 135) and x[1] is height(minus 66)\n",
    "        h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "        h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "        o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "        return o1\n",
    "    \n",
    "    def train(self, data, all_y_trues):\n",
    "        '''\n",
    "        --> data is a (n x 2) numpy array, n = # of samples in the dataset. Each row contains 2 elements, weight and height of a person\n",
    "        --> all_y_trues is a numpy array with n elements. Each element is the expected gender: 0 (male) or 1 (female) \n",
    "        --> Elements in all_y_trues correspond to those in data.\n",
    "        '''\n",
    "        \n",
    "        learn_rate = 0.1\n",
    "        epochs = 1001 # number of times to loop through the entire dataset\n",
    "        loss_list = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(data, all_y_trues):\n",
    "                h1_sum = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "                h1 = sigmoid(h1_sum)\n",
    "                \n",
    "                h2_sum = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "                h2 = sigmoid(h2_sum)\n",
    "                \n",
    "                o1_sum = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "                o1 = sigmoid(o1_sum)\n",
    "                y_pred= o1\n",
    "                \n",
    "                '''\n",
    "                Now we need to re- calculate the weights and biases in such a way that the loss decreases due to that change.\n",
    "                But for recalculating the new weights, we need dl/dw for each weight w.\n",
    "                The next steps will be used for that purpose \n",
    "                '''\n",
    "                \n",
    "                # --- Calculate partial derivatives.\n",
    "                # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "                d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "                \n",
    "                #  Neuron o1\n",
    "                d_ypred_d_w5 = h1 * deriv_sigmoid(o1_sum)\n",
    "                d_ypred_d_w6 = h2 * deriv_sigmoid(o1_sum)\n",
    "                d_ypred_d_b3 = deriv_sigmoid(o1_sum)\n",
    "                \n",
    "                d_ypred_d_h1 = self.w5 * deriv_sigmoid(o1_sum)\n",
    "                d_ypred_d_h2 = self.w6 * deriv_sigmoid(o1_sum)\n",
    "                \n",
    "                # Neuron h1\n",
    "                d_h1_d_w1 = x[0] * deriv_sigmoid(h1_sum)\n",
    "                d_h1_d_w2 = x[1] * deriv_sigmoid(h1_sum)\n",
    "                d_h1_d_b1= deriv_sigmoid(h1_sum)\n",
    "                \n",
    "                # Neuron h2\n",
    "                d_h2_d_w3 = x[0] * deriv_sigmoid(h2_sum)\n",
    "                d_h2_d_w4 = x[1] * deriv_sigmoid(h2_sum)\n",
    "                d_h2_d_b2= deriv_sigmoid(h2_sum)\n",
    "                \n",
    "                # --- After calculating the necessary derivatives we have to update the weights and biases\n",
    "                # Neuron h1\n",
    "                self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "                self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "                self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "                \n",
    "                # Neuron h2\n",
    "                self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "                self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "                self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "                # Neuron o1\n",
    "                self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "                self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "                self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "                \n",
    "            # Calculating the loss at the end of each epoch divisible by 10\n",
    "            if epoch % 10 == 0:\n",
    "                y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "                '''\n",
    "                np.apply_along_axis: Apply a function to 1-D slices along the given axis.\n",
    "                This will pass each 1-D row of data matrix into feedforward func. Output for each row will be stored in y_preds\n",
    "                '''\n",
    "                loss = mse_loss(all_y_trues, y_preds)\n",
    "                loss_list.append(loss)\n",
    "                print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "                \n",
    "        return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.283\n",
      "Epoch 10 loss: 0.207\n",
      "Epoch 20 loss: 0.153\n",
      "Epoch 30 loss: 0.115\n",
      "Epoch 40 loss: 0.087\n",
      "Epoch 50 loss: 0.068\n",
      "Epoch 60 loss: 0.054\n",
      "Epoch 70 loss: 0.044\n",
      "Epoch 80 loss: 0.036\n",
      "Epoch 90 loss: 0.031\n",
      "Epoch 100 loss: 0.026\n",
      "Epoch 110 loss: 0.023\n",
      "Epoch 120 loss: 0.021\n",
      "Epoch 130 loss: 0.018\n",
      "Epoch 140 loss: 0.017\n",
      "Epoch 150 loss: 0.015\n",
      "Epoch 160 loss: 0.014\n",
      "Epoch 170 loss: 0.013\n",
      "Epoch 180 loss: 0.012\n",
      "Epoch 190 loss: 0.011\n",
      "Epoch 200 loss: 0.010\n",
      "Epoch 210 loss: 0.010\n",
      "Epoch 220 loss: 0.009\n",
      "Epoch 230 loss: 0.009\n",
      "Epoch 240 loss: 0.008\n",
      "Epoch 250 loss: 0.008\n",
      "Epoch 260 loss: 0.007\n",
      "Epoch 270 loss: 0.007\n",
      "Epoch 280 loss: 0.007\n",
      "Epoch 290 loss: 0.006\n",
      "Epoch 300 loss: 0.006\n",
      "Epoch 310 loss: 0.006\n",
      "Epoch 320 loss: 0.006\n",
      "Epoch 330 loss: 0.005\n",
      "Epoch 340 loss: 0.005\n",
      "Epoch 350 loss: 0.005\n",
      "Epoch 360 loss: 0.005\n",
      "Epoch 370 loss: 0.005\n",
      "Epoch 380 loss: 0.005\n",
      "Epoch 390 loss: 0.004\n",
      "Epoch 400 loss: 0.004\n",
      "Epoch 410 loss: 0.004\n",
      "Epoch 420 loss: 0.004\n",
      "Epoch 430 loss: 0.004\n",
      "Epoch 440 loss: 0.004\n",
      "Epoch 450 loss: 0.004\n",
      "Epoch 460 loss: 0.004\n",
      "Epoch 470 loss: 0.004\n",
      "Epoch 480 loss: 0.003\n",
      "Epoch 490 loss: 0.003\n",
      "Epoch 500 loss: 0.003\n",
      "Epoch 510 loss: 0.003\n",
      "Epoch 520 loss: 0.003\n",
      "Epoch 530 loss: 0.003\n",
      "Epoch 540 loss: 0.003\n",
      "Epoch 550 loss: 0.003\n",
      "Epoch 560 loss: 0.003\n",
      "Epoch 570 loss: 0.003\n",
      "Epoch 580 loss: 0.003\n",
      "Epoch 590 loss: 0.003\n",
      "Epoch 600 loss: 0.003\n",
      "Epoch 610 loss: 0.003\n",
      "Epoch 620 loss: 0.003\n",
      "Epoch 630 loss: 0.003\n",
      "Epoch 640 loss: 0.002\n",
      "Epoch 650 loss: 0.002\n",
      "Epoch 660 loss: 0.002\n",
      "Epoch 670 loss: 0.002\n",
      "Epoch 680 loss: 0.002\n",
      "Epoch 690 loss: 0.002\n",
      "Epoch 700 loss: 0.002\n",
      "Epoch 710 loss: 0.002\n",
      "Epoch 720 loss: 0.002\n",
      "Epoch 730 loss: 0.002\n",
      "Epoch 740 loss: 0.002\n",
      "Epoch 750 loss: 0.002\n",
      "Epoch 760 loss: 0.002\n",
      "Epoch 770 loss: 0.002\n",
      "Epoch 780 loss: 0.002\n",
      "Epoch 790 loss: 0.002\n",
      "Epoch 800 loss: 0.002\n",
      "Epoch 810 loss: 0.002\n",
      "Epoch 820 loss: 0.002\n",
      "Epoch 830 loss: 0.002\n",
      "Epoch 840 loss: 0.002\n",
      "Epoch 850 loss: 0.002\n",
      "Epoch 860 loss: 0.002\n",
      "Epoch 870 loss: 0.002\n",
      "Epoch 880 loss: 0.002\n",
      "Epoch 890 loss: 0.002\n",
      "Epoch 900 loss: 0.002\n",
      "Epoch 910 loss: 0.002\n",
      "Epoch 920 loss: 0.002\n",
      "Epoch 930 loss: 0.002\n",
      "Epoch 940 loss: 0.002\n",
      "Epoch 950 loss: 0.002\n",
      "Epoch 960 loss: 0.002\n",
      "Epoch 970 loss: 0.002\n",
      "Epoch 980 loss: 0.002\n",
      "Epoch 990 loss: 0.002\n",
      "Epoch 1000 loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "# Train the neural network\n",
    "network = NeuralNetwork()\n",
    "losses = network.train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss\n",
    "\n",
    "epochs = np.arange(0, 1001, 10)\n",
    "\n",
    "plt.plot(epochs, losses)\n",
    "plt.title(\"Neural Network Analysis\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily: 0.968 Female\n",
      "Frank: 0.039 Female\n"
     ]
    }
   ],
   "source": [
    "# Making new predictions\n",
    "\n",
    "def gender(output):\n",
    "    if output > 0.9:\n",
    "        return 'Female'\n",
    "    elif output<0.1:\n",
    "        return 'Male'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Make some predictions\n",
    "emily = np.array([-7, -3]) # 128 pounds, 63 inches\n",
    "frank = np.array([20, 2])  # 155 pounds, 68 inches\n",
    "\n",
    "res1 = network.feedforward(emily)\n",
    "res2 = network.feedforward(frank)\n",
    "\n",
    "print(\"Emily: %.3f\" % res1, gender(res1)) \n",
    "print(\"Frank: %.3f\" % res2, gender(res1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click \n",
    "<a href=\"https://victorzhou.com/blog/intro-to-neural-networks/\">here</a>\n",
    "to visit the blog which I referred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
